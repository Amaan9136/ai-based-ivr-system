AI-based IVR System for Government Schools is a voice-interactive question-answering system that allows school students to call a phone number and get syllabus-based responses generated by an AI model using Retrieval-Augmented Generation (RAG).

## Project overview

This project implements an AI-powered Interactive Voice Response (IVR) system designed specifically for government and high school students following the NCERT syllabus.  When a student calls the IVR number and asks a question, the system retrieves relevant syllabus content using a RAG pipeline and generates an appropriate spoken answer using a local large language model.

## Key features

- Voice-based Q&A experience for students through a telephone-style IVR flow.
- NCERT syllabusâ€“aligned knowledge base covering topics for both high school and government school students.
- RAG pipeline built on ChromaDB to store, index, and retrieve syllabus chunks relevant to each student query.
- Local LLM inference using Ollama with the Mistral-based model and mxbai-embed-large for embeddings.
- Text-to-speech response, so the AI answers are spoken back to the caller in a natural IVR style.

## Tech stack

- Backend: Python-based server for handling IVR requests, query processing, and RAG orchestration.
- Vector store: ChromaDB for storing NCERT syllabus documents and performing semantic similarity search.
- LLM & embeddings: Ollama with Mistral model for generation and mxbai-embed-large for embedding NCERT text and user queries.
- Frontend/flow: HTML and related assets to design and visualize the IVR flow (for testing and debugging).

## RAG and IVR workflow

1. Student calls the IVR number and speaks a question related to the NCERT syllabus.
2. The system converts speech to text and sends the transcribed query to the backend.
3. The backend uses ChromaDB to retrieve top-matching syllabus passages from the NCERT dataset.
4. Retrieved passages and the student question are sent to the Ollama Mistral model, which generates a context-aware answer.
5. The generated answer is converted to speech and played back to the student via the IVR system.

## Installation and setup

1. Clone the repository and create a Python virtual environment.
2. Install Python dependencies:  
   - `pip install -r requirements.txt`  
   - `pip install ollama chromadb`
3. Install and configure Ollama locally, then pull the required models:  
   - `ollama pull mxbai-embed-large`  
   - `ollama pull mistral` (or your chosen Mistral-based model).
4. Prepare the NCERT syllabus dataset, chunk it into passages, and run the indexing script to populate ChromaDB.
5. Start the backend IVR server (for example, using the `ivr-server` directory entrypoint) and connect it to your telephony/IVR provider for handling real phone calls.

## Future improvements

- Replace local-only testing with scalable external LLM APIs when higher throughput is required.
- Extend syllabus coverage to additional classes, languages, and regional curricula used in different government schools.
- Add analytics on common student questions to help educators identify learning gaps across subjects and grades.
